{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'has_changed_dir' not in globals():\n",
    "    repo_path = os.path.abspath(os.path.join('..'))\n",
    "    \n",
    "    if repo_path not in sys.path:\n",
    "        sys.path.append(repo_path)\n",
    "    \n",
    "    os.chdir(repo_path)\n",
    "    \n",
    "    globals()['has_changed_dir'] = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import neunet\n",
    "from neunet.optim import SGD, Adadelta, Adagrad, Adam, Adamax, Momentum, NAdam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y):\n",
    "    return (1 - x) ** 2 + 100 * (y - x**2) ** 2\n",
    "\n",
    "\n",
    "def himmelblau(x, y):\n",
    "    return (x**2 + y - 11) ** 2 + (x + y**2 - 7) ** 2\n",
    "\n",
    "\n",
    "def matyas(x, y):\n",
    "    return 0.26 * (x**2 + y**2) - 0.48 * x * y\n",
    "\n",
    "\n",
    "def beale(x, y):\n",
    "    return (1.5 - x + x * y) ** 2 + (2.25 - x + x * y**2) ** 2 + (2.625 - x + x * y**3) ** 2\n",
    "\n",
    "\n",
    "def booth(x, y):\n",
    "    return (x + 2 * y - 7) ** 2 + (2 * x + y - 5) ** 2\n",
    "\n",
    "\n",
    "def goldstein_price(x, y):\n",
    "    return (1 + (x + y + 1) ** 2 * (19 - 14 * x + 3 * x**2 - 14 * y + 6 * x * y + 3 * y**2)) * (\n",
    "        30 + (2 * x - 3 * y) ** 2 * (18 - 32 * x + 12 * x**2 + 48 * y - 36 * x * y + 27 * y**2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(starting_point, optimizer, num_iterations, function, learning_rate):\n",
    "    points = [starting_point]\n",
    "    point = neunet.tensor(starting_point, requires_grad=True)\n",
    "    optimizer = optimizer(lr=learning_rate, params=[point])\n",
    "    for _ in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        y = function(point[0], point[1])\n",
    "        y.backward()\n",
    "        optimizer.step()\n",
    "        points.append([point[0].detach().numpy(), point[1].detach().numpy()])\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_point = np.array([-0.0, -7.0])  # (x, y)\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "optimizers = [Adam, SGD, RMSprop, NAdam, Momentum, Adagrad, Adadelta, Adamax]\n",
    "function = himmelblau\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "y = np.linspace(-10, 10, 1000)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = function(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.plot_surface(X, Y, Z, alpha=0.5, rstride=30, cstride=30, cmap=\"viridis\")\n",
    "\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    points = gradient_descent(starting_point, optimizer, num_iterations, function, learning_rate)\n",
    "    ax.plot(*points.T, function(*points.T), label=optimizer.__name__, color=f\"C{i}\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# Contour plot\n",
    "plt.contourf(\n",
    "    X, Y, Z, levels=500, extent=[0, 5, 0, 5], origin=\"lower\", cmap=\"coolwarm\"\n",
    ")  # cmaps = ['coolwarm', 'RdYlBu', 'viridis', 'jet', 'RdGy']\n",
    "plt.colorbar()\n",
    "contours = plt.contour(X, Y, Z, levels=10, extent=[0, 5, 0, 5], colors=\"black\")\n",
    "plt.clabel(contours, inline=True, fontsize=8)\n",
    "\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    points = gradient_descent(starting_point, optimizer, num_iterations, function, learning_rate)\n",
    "    plt.plot(points[:, 0], points[:, 1], label=optimizer.__name__, color=f\"C{i}\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
